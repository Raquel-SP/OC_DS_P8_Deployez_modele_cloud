{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7dc4ec6-be31-4c37-90fc-746e6a1a1a1b",
   "metadata": {
    "id": "028f4288-e455-48c2-ab6b-8557c83c2f48"
   },
   "source": [
    "\n",
    "# <font size=\"+3\"><span style='color:#861141'> **P8 - Déployez un modèle dans le cloud** </span></font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07450722-2805-4888-8e82-a33353711fdd",
   "metadata": {},
   "source": [
    "<a id='strat_spark_session'></a>\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "# <span style='background:#861141'><span style='color:white'>**Starting Spark Session** </span></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dceae79-4cc2-4edb-8010-91cbc72a0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'exécution de cette cellule démarre l'application Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de79f2-2417-4178-b027-e78f93dc0654",
   "metadata": {},
   "source": [
    "<u>We create the **SparkConext** under the varaible \"**sc**\"</u> :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27dc8cf-4721-437f-a517-288ceb1c8aa2",
   "metadata": {},
   "source": [
    "Let's display information about the spark session :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a5d950-fc6a-44da-9beb-95938a5010d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'driverMemory': '1000M', 'executorCores': 2, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1674810531637_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-33-95.eu-west-3.compute.internal:20888/proxy/application_1674810531637_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-43-210.eu-west-3.compute.internal:8042/node/containerlogs/container_1674810531637_0001_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95855407-9eb7-451f-9094-055a6c819f2f",
   "metadata": {
    "id": "66c1b2a3-ff31-42f4-8d80-8dbec803f88c"
   },
   "source": [
    "<a id='LOADING_LIBRARIES'></a>\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "# <span style='background:#861141'><span style='color:white'>**Loading de libraries** </span></span>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f57d6aa1-e277-4f02-b502-599fa1795092",
   "metadata": {},
   "source": [
    "Les packages nécessaires ont été installé via l'étape de bootstrap à l'instanciation du serveur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e628c29-a991-4889-9f8c-f96c38f7ebda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 09:38:03.845132: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# File system management\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import io\n",
    "import glob\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Image manipulation\n",
    "from PIL import Image\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Pyspark\n",
    "from pyspark.ml.feature import PCA, StandardScaler\n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split, udf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679dda0-9818-471d-85d7-3cb9a3a65cb5",
   "metadata": {
    "id": "5daf3f05-997b-42eb-9cc4-55ad1be08bf5",
    "tags": []
   },
   "source": [
    "<a id='preambule'></a>\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "# <span style='background:#861141'><span style='color:white'>**Préambule** </span></span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a3199e-9b2b-4da9-a506-4ae21a731d40",
   "metadata": {},
   "source": [
    "La très jeune start-up de l'AgriTech, nommée **\"Fruits!\", cherche à proposer des solutions innovantes pour la récolte des fruits**.\n",
    "\n",
    "La volonté de l’entreprise est de préserver la biodiversité des fruits en permettant des traitements spécifiques pour chaque espèce de fruits en développant des robots cueilleurs intelligents.\n",
    "\n",
    "La start-up souhaite dans un premier temps se faire connaître en mettant à disposition du grand public une application mobile qui permettrait aux utilisateurs de prendre en photo un fruit et d'obtenir des informations sur ce fruit.\n",
    "Pour la start-up, cette application permettrait de sensibiliser le grand public à la biodiversité des fruits et de mettre en place une première version du moteur de classification des images de fruits.\n",
    "De plus, le développement de l’application mobile permettra de construire une première version de l'architecture Big Data nécessaire.\n",
    "\n",
    "**Objectifs dans ce projet**\n",
    "\n",
    "* **Développer une première chaîne de traitement des données qui comprendra le preprocessing et une étape de réduction de dimension**. Tenir compte du fait que le volume de données va augmenter très rapidement après la livraison de ce projet, ce qui implique de:\n",
    "  * Déployer le traitement des données dans un **environnement Big Data**\n",
    "  * Développer les scripts en **pyspark** pour effectuer du **calcul distribué**\n",
    "\n",
    "Le projet va être réalisé **en 2 phases**, dans deux environnements différents.\n",
    "* Nous allons dans une première phase développer et exécuter notre code en **local**, en travaillant sur un nombre limité d'images à traiter.\n",
    "* Une fois les choix techniques validés, nous **déploierons** notre solution dans un **environnement Big Data en mode distribué**.\n",
    "Ce notebook correspond à la déuxieme phase.\n",
    "\n",
    "Un alternant a formalisé un document dans lequel il teste une première approche dans un environnement Big Data. Le notebook réalisé par l’alternant servira de point de départ pour construire une partie de la chaîne de traitement des données.\n",
    "\n",
    "\n",
    "**Mission**\n",
    "* Reprendre les travaux réalisés par l’alternant et de compléter la chaîne de traitement avec une étape de **réduction de dimension**.\n",
    "* Il n’est pas nécessaire d’entraîner un modèle pour le moment.\n",
    "* L’important est de mettre en place les premières briques de traitement qui serviront lorsqu’il faudra passer à l’échelle en termes de volume de données !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5720baef-0026-4040-8345-3a488c5cb11b",
   "metadata": {
    "id": "5daf3f05-997b-42eb-9cc4-55ad1be08bf5",
    "tags": []
   },
   "source": [
    "<a id='exploration_donnees'></a>\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "# <span style='background:#861141'><span style='color:white'>**Exploration des données** </span></span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9ae4ea-a31d-4b12-a4a5-904c42887fb6",
   "metadata": {},
   "source": [
    "Nous accédons directement à nos données sur S3 comme si elles étaient stockées localement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ffc527-4349-473b-b2c8-5a688036e434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH Project:     /home/raquelsp/Documents/Openclassrooms/P8_Fruits_modele_cloud/\n",
      "\n",
      "PATH_DataTrain:   /home/raquelsp/Documents/Openclassrooms/P8_Fruits_modele_cloud/P8_source/fruits/fruits-360_dataset/fruits-360/Training/\n",
      "\n",
      "PATH_DataTest:    /home/raquelsp/Documents/Openclassrooms/P8_Fruits_modele_cloud/P8_source/fruits/fruits-360_dataset/fruits-360/Test/\n"
     ]
    }
   ],
   "source": [
    "# Define the folder containing the files with the project data\n",
    "s3_P8 = \"s3://rsp-oc-p8-fruits/\"\n",
    "ATH_DataTest = s3_P8+'Test/'\n",
    "PATH_Result = s3_P8 + \"Results/\"\n",
    "\n",
    "\n",
    "print('PATH Project:     '+\\\n",
    "      s3_P8+'\\n\\nPATH_DataTest:    '+\\\n",
    "      PATH_DataTest+'\\n\\nPATH_Result:    '+\\\n",
    "      PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab9505-0e31-4290-a271-ec513160975a",
   "metadata": {
    "id": "5daf3f05-997b-42eb-9cc4-55ad1be08bf5",
    "tags": []
   },
   "source": [
    "<a id='traitement_donnees'></a>\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "# <span style='background:#861141'><span style='color:white'>**Traitement des données** </span></span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc165a19-932f-4863-8646-886e59f934ad",
   "metadata": {
    "id": "8cb63613-8dae-458a-96d5-e0770f00f407",
    "tags": []
   },
   "source": [
    "<a id='chargement_donnees'></a>\n",
    "\n",
    "## <span style='background:#7a1d2c'><span style='color:white'>Chargement des données</span></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b85cc89-9527-4db1-b9a3-842ddc52129e",
   "metadata": {},
   "source": [
    "* Les images sont chargées au format binaire, ce qui offre, plus de souplesse dans la façon de prétraiter les images.\n",
    "* Seuelement les fichiers dont l'extension est **jpg** seront chargés.\n",
    "* Les fichiers contenus contenus dans les sous-dossiers du dossier communiqué seront également chargés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e8dbb78-7650-40fb-86b2-ffc52d8bc518",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = spark.read.format(\"binaryFile\") \\\n",
    "  .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "  .option(\"recursiveFileLookup\", \"true\") \\\n",
    "  .load(PATH_DataTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b41c7ee-6882-4dcc-a19e-5802de908ee2",
   "metadata": {},
   "source": [
    "<u>Affichage des 5 premières images contenant</u> :\n",
    " - le path de l'image\n",
    " - la date et heure de sa dernière modification\n",
    " - sa longueur\n",
    " - son contenu encodé en valeur hexadécimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea932fd-a2d0-4f5c-ad23-3444eded0edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c904c1-5ee2-4861-a90a-4f43d937bd3a",
   "metadata": {},
   "source": [
    "<u>Seulement le **path** de l'image est conservé, une colonne contenant les **labels** de chaque image est ajouté</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "719e35a4-f8a8-455a-b6b6-860cf38887e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n",
      "None\n",
      "+----------------------------------------------------------------------------------------------------------+---------+\n",
      "|path                                                                                                      |label    |\n",
      "+----------------------------------------------------------------------------------------------------------+---------+\n",
      "|file:/home/raquelsp/Documents/Openclassrooms/P8_Fruits_modele_cloud/P8_travail/Test1/Raspberry/199_100.jpg|Raspberry|\n",
      "|file:/home/raquelsp/Documents/Openclassrooms/P8_Fruits_modele_cloud/P8_travail/Test1/Raspberry/200_100.jpg|Raspberry|\n",
      "|file:/home/raquelsp/Documents/Openclassrooms/P8_Fruits_modele_cloud/P8_travail/Test1/Raspberry/81_100.jpg |Raspberry|\n",
      "|file:/home/raquelsp/Documents/Openclassrooms/P8_Fruits_modele_cloud/P8_travail/Test1/Raspberry/111_100.jpg|Raspberry|\n",
      "|file:/home/raquelsp/Documents/Openclassrooms/P8_Fruits_modele_cloud/P8_travail/Test1/Raspberry/213_100.jpg|Raspberry|\n",
      "+----------------------------------------------------------------------------------------------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n",
    "print(images.printSchema())\n",
    "print(images.select('path','label').show(5,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73997b5b-4dda-419b-8ae8-f8f0fac1d840",
   "metadata": {
    "id": "8cb63613-8dae-458a-96d5-e0770f00f407",
    "tags": []
   },
   "source": [
    "<a id='preparation_modele'></a>\n",
    "\n",
    "## <span style='background:#7a1d2c'><span style='color:white'>Préparation du modèle</span></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffe9fae-7f2c-452c-afc9-c7a1e5d6485a",
   "metadata": {},
   "source": [
    "On a décidé de travailler avec du transfert learning. Le transfert learning consiste à utiliser la connaissance déjà acquise par un modèle entraîné (ici **MobileNetV2**) pour l'adapter à notre problématique.\n",
    "Nous allons fournir au modèle nos images, et nous allons récupérer l'avant dernière couche du modèle. Cela permettra de réaliser une première version du moteur pour la classification des images des fruits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ee07ee5-fb8d-4b85-aec3-e1fe39d7ecad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 09:38:20.322354: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 09:38:20.323222: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2(weights='imagenet',\n",
    "                    include_top=True,\n",
    "                    input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4dafb21-0d22-4e57-a9bb-8507a1c92761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model = Model(inputs=model.input,\n",
    "                  outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebcfc412-2946-4f27-919b-b8afa5847944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brodcast_weights = sc.broadcast(new_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3878a987-e715-4336-8282-e61a6f638ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bdc22b-4cd6-40bc-a3bc-7927c311e1a8",
   "metadata": {},
   "source": [
    "<u>Mettons cela sous forme de fonction</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5a4b1c3-0442-4436-a47a-6b788705b8cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns a MobileNetV2 model with top layer removed \n",
    "    and broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(weights='imagenet',\n",
    "                        include_top=True,\n",
    "                        input_shape=(224, 224, 3))\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    new_model = Model(inputs=model.input,\n",
    "                  outputs=model.layers[-2].output)\n",
    "    new_model.set_weights(brodcast_weights.value)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8b755-8da0-482b-abca-ff2ddb55e23b",
   "metadata": {
    "id": "8cb63613-8dae-458a-96d5-e0770f00f407",
    "tags": []
   },
   "source": [
    "<a id='chargement_featurisation_udf'></a>\n",
    "\n",
    "## <span style='background:#7a1d2c'><span style='color:white'>Définition du processus de chargement des images et application de leur featurisation à travers l'utilisation de pandas UDF</span></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6018ad-6869-4b33-b2d6-0a3637782cad",
   "metadata": {},
   "source": [
    "Le notebook définit la logique par étapes, jusqu'à Pandas UDF.\n",
    "\n",
    "<u>L'empilement des appels est la suivante</u> :\n",
    "\n",
    "- Pandas UDF\n",
    "  - featuriser une série d'images pd.Series\n",
    "   - prétraiter une image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a2c782b-c905-48fd-9499-468a5b20ee0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raquelsp/anaconda3/envs/venvP8/lib/python3.7/site-packages/pyspark/sql/pandas/functions.py:392: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  \"in the future releases. See SPARK-28264 for more details.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Resize images to 224x224\n",
    "def preprocess(content):\n",
    "    \"\"\"\n",
    "    Preprocesses raw image bytes for prediction.\n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)\n",
    "\n",
    "# Featurize images and return a series of vectors (flattened tensors)\n",
    "def featurize_series(model, content_series):\n",
    "    \"\"\"\n",
    "    Featurize a pd.Series of raw images using the input model.\n",
    "    :return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    input = np.stack(content_series.map(preprocess))\n",
    "    preds = model.predict(input)\n",
    "    # For some layers, output features will be multi-dimensional tensors.\n",
    "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)\n",
    "\n",
    "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
    "def featurize_udf(content_series_iter):\n",
    "    '''\n",
    "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
    "\n",
    "    :param: content_series_iter, This argument is an iterator over batches of data, where each batch\n",
    "                              is a pandas Series of image data.\n",
    "    '''\n",
    "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
    "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
    "    model = model_fn()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_series(model, content_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ac112-7559-4cab-b2bc-d360f008eb6b",
   "metadata": {
    "id": "8cb63613-8dae-458a-96d5-e0770f00f407",
    "tags": []
   },
   "source": [
    "<a id='execution_extraction_feat'></a>\n",
    "\n",
    "## <span style='background:#7a1d2c'><span style='color:white'>Exécution des actions d'extraction de features</span></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fcc93-c8a5-4389-ad96-59c133b577e3",
   "metadata": {},
   "source": [
    "Les Pandas UDF, sur de grands enregistrements (par exemple, de très grandes images), peuvent rencontrer des erreurs de type Out Of Memory (OOM).\n",
    "Dans le cas où de teller erreurs apparaitrent, la ligne de code dans la cellule ci-dessous, permets de retuire la taille du lot Arrow via 'maxRecordsPerBatch'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51bc943b-d04b-41ef-9bb3-9bf6d9bfa293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581d47e8-0918-4507-98ac-b31027db8011",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant exécuter la featurisation sur l'ensemble de notre DataFrame Spark.<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfa679cb-94c7-48e8-8201-a291a59d6904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = images.repartition(24).select(col(\"path\"),\n",
    "                                            col(\"label\"),\n",
    "                                            featurize_udf(\"content\").alias(\"features\")\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026f325-4442-46d2-bcf0-f7dd1048c09a",
   "metadata": {},
   "source": [
    "<u>Rappel du PATH où seront inscrits les fichiers au format \"**parquet**\" <br />\n",
    "contenant nos résultats, à savoir, un DataFrame contenant 3 colonnes</u> :\n",
    " 1. Path des images\n",
    " 2. Label de l'image\n",
    " 3. Vecteur de caractéristiques de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6eae5805-59e2-4bc6-9848-fbc5ad49c197",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raquelsp/Documents/Openclassrooms/P8_Fruits_modele_cloud/P8_travail/Results_local/\n"
     ]
    }
   ],
   "source": [
    "print(PATH_Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c87553a-2ca0-4645-8ddc-43d8bb03df3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 09:38:23.204958: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 09:38:24.228809: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 09:38:24.231245: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+\n",
      "|                path|             label|            features|\n",
      "+--------------------+------------------+--------------------+\n",
      "|file:/home/raquel...|         Raspberry|[0.29254088, 1.06...|\n",
      "|file:/home/raquel...|        Strawberry|[2.20994, 0.09814...|\n",
      "|file:/home/raquel...|        Strawberry|[1.6356167, 0.0, ...|\n",
      "|file:/home/raquel...|             Peach|[0.13757613, 0.0,...|\n",
      "|file:/home/raquel...|Tomato not Ripened|[0.0, 0.4384215, ...|\n",
      "+--------------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 838ms/step\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "features_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fc3aab-92de-4082-bdf5-bdec7d83d23e",
   "metadata": {
    "id": "8cb63613-8dae-458a-96d5-e0770f00f407",
    "tags": []
   },
   "source": [
    "<a id='PCA'></a>\n",
    "\n",
    "## <span style='background:#7a1d2c'><span style='color:white'>Réduction des dimensions via PCA</span></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca32df-197c-4926-83f9-2f2e957c8d8d",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6baa9760-2a19-4c21-8473-63edad6dcbae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<a id='preparation_donnees_pca'></a>\n",
    "\n",
    "### <font size=\"+2\" color=\"#63202b\"><b>Préparation des données<b></font><br><a name=\"Tokenization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48589eb5-1b95-4693-8a0a-0e7b8bb52378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 09:38:26.977887: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 09:38:28.010429: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 09:38:28.012499: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "1/1 [==============================] - 1s 767ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+--------------------+\n",
      "|                path|             label|            features|      vectorFeatures|\n",
      "+--------------------+------------------+--------------------+--------------------+\n",
      "|file:/home/raquel...|         Raspberry|[0.29254088, 1.06...|[0.29254087805747...|\n",
      "|file:/home/raquel...|        Strawberry|[2.20994, 0.09814...|[2.20993995666503...|\n",
      "|file:/home/raquel...|        Strawberry|[1.6356167, 0.0, ...|[1.63561666011810...|\n",
      "|file:/home/raquel...|             Peach|[0.13757613, 0.0,...|[0.13757613301277...|\n",
      "|file:/home/raquel...|Tomato not Ripened|[0.0, 0.4384215, ...|[0.0,0.4384214878...|\n",
      "+--------------------+------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# First step is to convert our features arrays into vectors\n",
    "array_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "df_with_vectors = features_df.select(\n",
    "    features_df[\"path\"],\n",
    "    features_df[\"label\"],\n",
    "    features_df[\"features\"],\n",
    "    array_to_vector_udf(features_df[\"features\"]).alias(\"vectorFeatures\"),\n",
    ")\n",
    "# show the 5 first values :\n",
    "df_with_vectors.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4065e42f-760f-49f5-b506-a08cc115f35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 580ms/step               (0 + 1) / 20]\n",
      "1/1 [==============================] - 1s 625ms/step               (1 + 1) / 20]\n",
      "1/1 [==============================] - 1s 613ms/step               (2 + 1) / 20]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe76c593a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 899ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe76c593560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 689ms/step\n",
      "1/1 [==============================] - 1s 677ms/step               (5 + 1) / 20]\n",
      "1/1 [==============================] - 1s 645ms/step               (6 + 1) / 20]\n",
      "1/1 [==============================] - 1s 763ms/step               (7 + 1) / 20]\n",
      "1/1 [==============================] - 1s 711ms/step               (8 + 1) / 20]\n",
      "1/1 [==============================] - 1s 627ms/step               (9 + 1) / 20]\n",
      "1/1 [==============================] - 1s 629ms/step              (10 + 1) / 20]\n",
      "1/1 [==============================] - 1s 771ms/step              (11 + 1) / 20]\n",
      "1/1 [==============================] - 1s 654ms/step              (12 + 1) / 20]\n",
      "1/1 [==============================] - 1s 616ms/step              (13 + 1) / 20]\n",
      "1/1 [==============================] - 1s 730ms/step              (14 + 1) / 20]\n",
      "1/1 [==============================] - 1s 585ms/step              (15 + 1) / 20]\n",
      "1/1 [==============================] - 1s 589ms/step==>           (16 + 1) / 20]\n",
      "1/1 [==============================] - 1s 629ms/step=====>        (17 + 1) / 20]\n",
      "1/1 [==============================] - 1s 583ms/step========>     (18 + 1) / 20]\n",
      "1/1 [==============================] - 1s 590ms/step===========>  (19 + 1) / 20]\n",
      "1/1 [==============================] - 1s 579ms/step                (0 + 1) / 1]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|                path|             label|            features|      vectorFeatures|      scaledFeatures|\n",
      "+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|file:/home/raquel...|         Raspberry|[0.29254088, 1.06...|[0.29254087805747...|[-0.2479661194709...|\n",
      "|file:/home/raquel...|        Strawberry|[2.20994, 0.09814...|[2.20993995666503...|[3.09032401311497...|\n",
      "|file:/home/raquel...|        Strawberry|[1.6356167, 0.0, ...|[1.63561666011810...|[2.09039769878233...|\n",
      "|file:/home/raquel...|             Peach|[0.13757613, 0.0,...|[0.13757613301277...|[-0.5177676881965...|\n",
      "|file:/home/raquel...|Tomato not Ripened|[0.0, 0.4384215, ...|[0.0,0.4384214878...|[-0.7572947915732...|\n",
      "+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Second step is to scale the data before applying the PCA process\n",
    "scaler = StandardScaler(inputCol=\"vectorFeatures\",\n",
    "                        outputCol=\"scaledFeatures\",\n",
    "                        withMean=True, withStd=True\n",
    "                        ).fit(df_with_vectors)\n",
    "\n",
    "# when we transform the dataframe, the old feature will still remain in it\n",
    "df_scaled = scaler.transform(df_with_vectors)\n",
    "# show the 5 first values :\n",
    "df_scaled.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5deea-32aa-4def-88b5-2020ada005d1",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "213a2e18-9994-4a2c-8645-b9cb0ba54fb7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<a id='reduc_dim'></a>\n",
    "\n",
    "### <font size=\"+2\" color=\"#63202b\"><b>Réduction de dimensions via PCA<b></font><br><a name=\"Tokenization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea7b1618-3688-409e-aa95-b081974a6c6f",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b6d755b3-bddb-424b-9b55-fa5cd8b031e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 728ms/step                (0 + 1) / 1]\n",
      "1/1 [==============================] - 1s 872ms/step                (0 + 1) / 1]\n",
      "1/1 [==============================] - 1s 1s/step                  (0 + 1) / 20]\n",
      "1/1 [==============================] - 1s 903ms/step               (1 + 1) / 20]\n",
      "1/1 [==============================] - 1s 724ms/step               (2 + 1) / 20]\n",
      "1/1 [==============================] - 1s 792ms/step               (3 + 1) / 20]\n",
      "1/1 [==============================] - 1s 999ms/step               (4 + 1) / 20]\n",
      "1/1 [==============================] - 1s 939ms/step               (5 + 1) / 20]\n",
      "1/1 [==============================] - 1s 836ms/step               (6 + 1) / 20]\n",
      "1/1 [==============================] - 1s 712ms/step               (7 + 1) / 20]\n",
      "1/1 [==============================] - 1s 755ms/step               (8 + 1) / 20]\n",
      "1/1 [==============================] - 1s 659ms/step               (9 + 1) / 20]\n",
      "1/1 [==============================] - 1s 729ms/step              (10 + 1) / 20]\n",
      "1/1 [==============================] - 1s 664ms/step              (11 + 1) / 20]\n",
      "1/1 [==============================] - 1s 711ms/step              (12 + 1) / 20]\n",
      "1/1 [==============================] - 1s 801ms/step              (13 + 1) / 20]\n",
      "1/1 [==============================] - 1s 691ms/step              (14 + 1) / 20]\n",
      "1/1 [==============================] - 1s 678ms/step>             (15 + 1) / 20]\n",
      "1/1 [==============================] - 1s 688ms/step==>           (16 + 1) / 20]\n",
      "1/1 [==============================] - 1s 720ms/step=====>        (17 + 1) / 20]\n",
      "1/1 [==============================] - 1s 682ms/step========>     (18 + 1) / 20]\n",
      "1/1 [==============================] - 1s 685ms/step===========>  (19 + 1) / 20]\n",
      "1/1 [==============================] - 1s 689ms/step                (0 + 1) / 1]\n",
      "1/1 [==============================] - 1s 657ms/step               (0 + 1) / 20]\n",
      "1/1 [==============================] - 1s 693ms/step               (1 + 1) / 20]\n",
      "1/1 [==============================] - 1s 619ms/step               (2 + 1) / 20]\n",
      "1/1 [==============================] - 1s 649ms/step               (3 + 1) / 20]\n",
      "1/1 [==============================] - 1s 630ms/step               (4 + 1) / 20]\n",
      "1/1 [==============================] - 1s 645ms/step               (5 + 1) / 20]\n",
      "1/1 [==============================] - 1s 656ms/step               (6 + 1) / 20]\n",
      "1/1 [==============================] - 1s 693ms/step               (7 + 1) / 20]\n",
      "1/1 [==============================] - 1s 701ms/step               (8 + 1) / 20]\n",
      "1/1 [==============================] - 1s 665ms/step               (9 + 1) / 20]\n",
      "1/1 [==============================] - 1s 691ms/step              (10 + 1) / 20]\n",
      "1/1 [==============================] - 1s 700ms/step              (11 + 1) / 20]\n",
      "1/1 [==============================] - 1s 632ms/step              (12 + 1) / 20]\n",
      "1/1 [==============================] - 1s 629ms/step              (13 + 1) / 20]\n",
      "1/1 [==============================] - 1s 643ms/step              (14 + 1) / 20]\n",
      "1/1 [==============================] - 1s 605ms/step>             (15 + 1) / 20]\n",
      "1/1 [==============================] - 1s 631ms/step==>           (16 + 1) / 20]\n",
      "1/1 [==============================] - 1s 618ms/step=====>        (17 + 1) / 20]\n",
      "1/1 [==============================] - 1s 609ms/step========>     (18 + 1) / 20]\n",
      "1/1 [==============================] - 1s 619ms/step===========>  (19 + 1) / 20]\n",
      "23/08/25 09:41:53 WARN DAGScheduler: Broadcasting large task binary with size 1352.1 KiB\n",
      "1/1 [==============================] - 1s 643ms/step                (0 + 1) / 1]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                path|             label|            features|      vectorFeatures|      scaledFeatures|         pcaFeatures|\n",
      "+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|file:/home/raquel...|         Raspberry|[0.29254088, 1.06...|[0.29254087805747...|[-0.2479661194709...|[-18.915042887680...|\n",
      "|file:/home/raquel...|        Strawberry|[2.20994, 0.09814...|[2.20993995666503...|[3.09032401311497...|[-19.988846857832...|\n",
      "|file:/home/raquel...|        Strawberry|[1.6356167, 0.0, ...|[1.63561666011810...|[2.09039769878233...|[-31.014341250894...|\n",
      "|file:/home/raquel...|             Peach|[0.13757613, 0.0,...|[0.13757613301277...|[-0.5177676881965...|[-3.0016836093650...|\n",
      "|file:/home/raquel...|Tomato not Ripened|[0.0, 0.4384215, ...|[0.0,0.4384214878...|[-0.7572947915732...|[3.81594761774128...|\n",
      "+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We will use the optimal number of components for explaining 95% of variance\n",
    "# identified during the local development\n",
    "n_components = 128\n",
    "\n",
    "# Apply the PCA with n_components\n",
    "pca = PCA(k=n_components, inputCol='scaledFeatures', outputCol='pcaFeatures')\n",
    "\n",
    "model_pca = pca.fit(df_scaled)\n",
    "df_pca = model_pca.transform(df_scaled)\n",
    "\n",
    "# show the 5 first values :\n",
    "df_pca.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bff578-d263-40f6-bbdb-d01e22ab36c4",
   "metadata": {
    "id": "8cb63613-8dae-458a-96d5-e0770f00f407",
    "tags": []
   },
   "source": [
    "<a id='enreg_resultats'></a>\n",
    "\n",
    "## <span style='background:#7a1d2c'><span style='color:white'>Enregistrement des résultats</span></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b2b64-2536-4b30-9e40-c981478cd41d",
   "metadata": {},
   "source": [
    "<u>Enregistrement des données traitées au format \"**parquet**\"</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e447cae4-a1aa-4add-b412-df8e9c44e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_pca.select([\"path\", \"label\", \"pcaFeatures\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b868cec1-3933-4523-b566-ba1426ec0aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/25 09:41:55 WARN DAGScheduler: Broadcasting large task binary with size 1547.3 KiB\n",
      "1/1 [==============================] - 1s 613ms/step               (0 + 1) / 20]\n",
      "1/1 [==============================] - 1s 661ms/step               (1 + 1) / 20]\n",
      "1/1 [==============================] - 1s 597ms/step               (2 + 1) / 20]\n",
      "1/1 [==============================] - 1s 624ms/step               (3 + 1) / 20]\n",
      "1/1 [==============================] - 1s 853ms/step               (4 + 1) / 20]\n",
      "1/1 [==============================] - 1s 661ms/step               (5 + 1) / 20]\n",
      "1/1 [==============================] - 1s 734ms/step               (6 + 1) / 20]\n",
      "1/1 [==============================] - 1s 863ms/step               (7 + 1) / 20]\n",
      "1/1 [==============================] - 1s 671ms/step               (8 + 1) / 20]\n",
      "1/1 [==============================] - 1s 826ms/step               (9 + 1) / 20]\n",
      "1/1 [==============================] - 1s 808ms/step              (10 + 1) / 20]\n",
      "1/1 [==============================] - 1s 699ms/step              (11 + 1) / 20]\n",
      "1/1 [==============================] - 1s 920ms/step              (12 + 1) / 20]\n",
      "1/1 [==============================] - 1s 847ms/step              (13 + 1) / 20]\n",
      "1/1 [==============================] - 1s 782ms/step              (14 + 1) / 20]\n",
      "1/1 [==============================] - 1s 822ms/step>             (15 + 1) / 20]\n",
      "1/1 [==============================] - 1s 749ms/step==>           (16 + 1) / 20]\n",
      "1/1 [==============================] - 1s 925ms/step=====>        (17 + 1) / 20]\n",
      "1/1 [==============================] - 1s 771ms/step========>     (18 + 1) / 20]\n",
      "1/1 [==============================] - 1s 903ms/step===========>  (19 + 1) / 20]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_results.write.mode(\"overwrite\").parquet(PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c395f457-6b75-4a12-ac9c-a87436531e5f",
   "metadata": {
    "id": "8cb63613-8dae-458a-96d5-e0770f00f407",
    "tags": []
   },
   "source": [
    "<a id='validation'></a>\n",
    "\n",
    "## <span style='background:#7a1d2c'><span style='color:white'>Chargement des données enregistrées et validation du résultat</span></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f539251-c6e7-43a5-b41a-392daafd94a6",
   "metadata": {},
   "source": [
    "<u>On charge les données fraichement enregistrées dans un **DataFrame Pandas**</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9069fa85-4826-414e-b110-872dd73a29cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(PATH_Result).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf8b6f0-8ba2-447c-8ee2-2f52c405d226",
   "metadata": {},
   "source": [
    "<u>On affiche les 5 premières lignes du DataFrame</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8627fcc5-1f70-4464-a69f-552efc4fbffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>pcaFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file:/home/raquelsp/Documents/Openclassrooms/P...</td>\n",
       "      <td>Raspberry</td>\n",
       "      <td>[-19.29533577800976, 2.810266574434207, 13.612...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file:/home/raquelsp/Documents/Openclassrooms/P...</td>\n",
       "      <td>Raspberry</td>\n",
       "      <td>[-15.856456261290123, 5.086231665583818, 1.284...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file:/home/raquelsp/Documents/Openclassrooms/P...</td>\n",
       "      <td>Peach</td>\n",
       "      <td>[-5.279906953913183, -8.526506257805092, -6.65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file:/home/raquelsp/Documents/Openclassrooms/P...</td>\n",
       "      <td>Mangostan</td>\n",
       "      <td>[-2.343878066472722, -0.3323713964594619, -9.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file:/home/raquelsp/Documents/Openclassrooms/P...</td>\n",
       "      <td>Peach</td>\n",
       "      <td>[-2.823781675367395, -8.785769088483162, -3.59...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path      label  \\\n",
       "0  file:/home/raquelsp/Documents/Openclassrooms/P...  Raspberry   \n",
       "1  file:/home/raquelsp/Documents/Openclassrooms/P...  Raspberry   \n",
       "2  file:/home/raquelsp/Documents/Openclassrooms/P...      Peach   \n",
       "3  file:/home/raquelsp/Documents/Openclassrooms/P...  Mangostan   \n",
       "4  file:/home/raquelsp/Documents/Openclassrooms/P...      Peach   \n",
       "\n",
       "                                         pcaFeatures  \n",
       "0  [-19.29533577800976, 2.810266574434207, 13.612...  \n",
       "1  [-15.856456261290123, 5.086231665583818, 1.284...  \n",
       "2  [-5.279906953913183, -8.526506257805092, -6.65...  \n",
       "3  [-2.343878066472722, -0.3323713964594619, -9.4...  \n",
       "4  [-2.823781675367395, -8.785769088483162, -3.59...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6899a4b1-dc7f-4843-bef5-d228d18795d2",
   "metadata": {},
   "source": [
    "<u>On valide que la dimension des features est bien equivalente au nombre de composantes rétenu (128)</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6851326a-4786-46c4-aa1f-02300165e644",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df.loc[0, \"pcaFeatures\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573e8e86-87b8-46d6-8150-ac926cea9896",
   "metadata": {},
   "source": [
    "et que le numéro d'images traitées est :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90a0bb07-6d9b-4ba4-a343-ab52ccc5100a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c2565-5d61-4a77-ba4d-373cef9702a2",
   "metadata": {
    "id": "5daf3f05-997b-42eb-9cc4-55ad1be08bf5",
    "tags": []
   },
   "source": [
    "<a id='conclusions'></a>\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "# <span style='background:#861141'><span style='color:white'>**Conclusions** </span></span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd16199a-22d3-4cd8-b858-5cf7ab412629",
   "metadata": {},
   "source": [
    "Ce notebook s'intègre dans la deuxième phase du projet qui consiste à **créer unn réel cluster de calculs**.\n",
    "L'objectif était de pouvoir **anticiper une future augmentation de la charge de travail**.\n",
    "\n",
    "Le choix retenu a été l'utilisation du prestataire de services **Amazon Web Services** qui nous permet de louer à la demande de la puissance de calculs, pour un coût tout à fait acceptable.\n",
    "En plus d'être rapide et simple à mettre en place, nous avons la certitude du bon fonctionnement de la solution, celle-ci ayant été préalablement validé par les ingénieurs d'Amazon.\n",
    "\n",
    "Nous avons en utilisé le **service EMR** (Plateforme As A Service PAAS) qui permet d'instancier plusieurs serveurs (un **cluster**) sur lesquels nous avons installé et configuré plusieurs programmes et librairies nécessaires au projet comme Spark, Hadoop, JupyterHub ainsi que la librairie TensorFlow.\n",
    "\n",
    "Nous avons exécuté le notebook qui avait été validé en local.\n",
    "Nous avons exécuté le traitement sur l'ensemble des images du dossier \"Test\".\n",
    "\n",
    "Nous avons opté pour le service Amazon S3 pour stocker les données de notre projet. S3 offre, pour un faible coût, toutes les conditions dont nous avons besoin pour stocker\n",
    "et exploiter de manière efficace nos données.\n",
    "L'espace alloué est potentiellement illimité, mais les coûts seront fonction de l'espace utilisé.\n",
    "\n",
    "Il sera **simple de faire face à une monté de la charge de travail** en redimensionnant simplement notre cluster de machines (horizontalement et/ou verticalement au besoin), **les coûts augmenteront proportionnellement** mais resteront nettement inférieurs aux coûts engendrés par l'achat de matériels ou par la location de serveurs dédiés."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvP8",
   "language": "python",
   "name": "venvp8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
